<!DOCTYPE html>
<html>
<head>
  <title>Selfie Segmentation Mask Rendering with GLSL Shader</title>
</head>
<body>
  <canvas id="canvas" width="640" height="480"></canvas>
  <script type="module">
    // Import the necessary modules from the MediaPipe CDN
    import { SelfieSegmentation } from 'https://cdn.jsdelivr.net/npm/@mediapipe@latest/selfie_segmentation';

    // Get references to canvas element and its 2D context
    const canvasElement = document.getElementById('canvas');
    const canvasCtx = canvasElement.getContext('2d');

    // Create a WebGL context
    const gl = canvasElement.getContext('webgl');

    // Access the webcam stream and set it as the source for the video element
    async function initCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        videoElement.srcObject = stream;
      } catch (error) {
        console.error('Error accessing webcam:', error);
      }
    }

    // Start selfie segmentation
    async function startSelfieSegmentation() {
      const selfieSegmentation = new SelfieSegmentation();
      await selfieSegmentation.setOptions({ modelSelection: 1 }); // 0 for general, 1 for landscape portrait

      // Process segmentation results
      async function handleSegmentationResults(results) {
        // Use GLSL shader to render the mask on the canvas
        renderMaskWithShader(results.segmentationMask);
        requestAnimationFrame(detectSelfieSegmentation);
      }

      // Main function to detect selfie segmentation in the video stream
      async function detectSelfieSegmentation() {
        await selfieSegmentation.send({ image: videoElement });

        // Get segmentation results
        await selfieSegmentation.recv().then(handleSegmentationResults);
      }

      requestAnimationFrame(detectSelfieSegmentation);
    }

    // Render the mask using a GLSL shader
    function renderMaskWithShader(segmentationMask) {
      // Set up the GLSL shader program
      const vertexShaderSource = `
        attribute vec2 a_position;
        varying vec2 v_texCoord;
        void main() {
          gl_Position = vec4(a_position, 0, 1);
          v_texCoord = a_position * 0.5 + 0.5;
        }
      `;

      const fragmentShaderSource = `
        precision mediump float;
        uniform sampler2D u_image;
        uniform sampler2D u_mask;
        varying vec2 v_texCoord;
        void main() {
          vec4 imageColor = texture2D(u_image, v_texCoord);
          vec4 maskColor = texture2D(u_mask, v_texCoord);
          gl_FragColor = vec4(imageColor.rgb, maskColor.r);
        }
      `;

      const vertexShader = gl.createShader(gl.VERTEX_SHADER);
      gl.shaderSource(vertexShader, vertexShaderSource);
      gl.compileShader(vertexShader);

      const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
      gl.shaderSource(fragmentShader, fragmentShaderSource);
      gl.compileShader(fragmentShader);

      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);
      gl.useProgram(program);

      // Create a quad to cover the canvas
      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      const positions = [-1, -1, 1, -1, -1, 1, 1, 1];
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);
      const positionAttributeLocation = gl.getAttribLocation(program, 'a_position');
      gl.enableVertexAttribArray(positionAttributeLocation);
      gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);

      // Set up the texture uniforms
      const imageTexture = createTextureFromCanvas(videoElement);
      const maskTexture = createTextureFromCanvas(segmentationMask);
      const imageUniformLocation = gl.getUniformLocation(program, 'u_image');
      const maskUniformLocation = gl.getUniformLocation(program, 'u_mask');
      gl.uniform1i(imageUniformLocation, 0);
      gl.uniform1i(maskUniformLocation, 1);

      // Bind the textures
      gl.activeTexture(gl.TEXTURE0);
      gl.bindTexture(gl.TEXTURE_2D, imageTexture);
      gl.activeTexture(gl.TEXTURE1);
      gl.bindTexture(gl.TEXTURE_2D, maskTexture);

      // Draw the quad to render the result on the canvas
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }

    // Create a texture from a canvas
    function createTextureFromCanvas(canvas) {
      const texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, texture);
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, canvas);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      return texture;
    }

    // Start camera and selfie segmentation when the page loads
    window.onload = async () => {
      await initCamera();
      startSelfieSegmentation();
    };
  </script>
</body>
</html>
